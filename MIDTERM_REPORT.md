
# geoguess-ml
![image](https://github.gatech.edu/storage/user/60157/files/a4fe5357-46df-4f2b-8462-99021752c736)
# Intro
This project involves the ability to discern the location of an image using machine learning. There has been a decent amount of work done in this field. In 2016, Google developed an AI called Planet which aimed to recognize the location of a photo anywhere in the world. At the University of Colorado Boulder, students aimed to create an AI which could determine the location of a photo in the continental U.S states(Theethira). However, this area of ML is far from being perfected. The Google Planet AI could only detect location with a country-accuracy of 28%(Brokaw). 
# Motivation
The motivation of this project is being able to geotag images without any additional information other than the pixels in the image. The ability to do this could have widespread uses, from tagging photos on social media sites to identifying the location of criminals or fugitives using only a small set of images. 
# Data Collection Methods
We utilized the Google StreetView API to generate 20,000 street images from a selection of ten countries. Specifically, we got 2,000 images from each of the United States, Russia, Great Britain, South Africa, Argentina, Japan, Australia, Portugal, Israel, and Kenya. Our intention with this selection of countries was to have enough geographic diversity to train the model on various features/characteristics across the world, while also maintaining some countries with similar features (e.g. South Africa and Kenya) to examine how accurately the model differentiated between these countries. In order to get the data from individual countries, we created polygons with latitude/longitude bounds and verified whether the collected image was from the intended country or not.
# Algorithms and Methods
For dimensionality reduction, we used principal component analysis (PCA) from the scikit-learn module, and reduced the number of features present to 20 (this is a hyperparameter that we can modify for our final report) for every image. We then input the modified image data into a convolutional neural network implemented through PyTorch libraries and packages; this CNN contains convolutional, ReLU, max pooling, and fully connected layers (Swapna). We then used a cross entropy-based loss function, and utilized gradient descent and backpropagation to update our parameters for each epoch.

![general CNN architecture](https://i0.wp.com/developersbreach.com/wp-content/uploads/2020/08/cnn_banner.png?fit=1200%2C564&ssl=1)
*Similar CNN Architecture*   [source](https://developersbreach.com/convolution-neural-network-deep-learning/)
# Discussion and Expected Results
There will be a few constraints put on our results. We will not consider the exact location of the image. Instead, we will consider if the correct country was chosen. In other predictive uses of convolutional neural networks, well-developed CNNs have been able to outperform humans by around 33 percent (Mrázová et al). Accounting for the unique characteristics of our project in addition to knowledge/time constraints, we hypothesize that our algorithm will provide correct predictions at a rate slightly greater than an educated human.
In order to quantify the overall accuracy of our model, we will use an accuracy score function which computes what percentage of predictions are correct. As a measure of how well our model matches our hypothesis, we will compare the accuracy of our algorithm and the accuracy of a human participant in geotagging a set of images. Our algorithm will be successful if it produces correct guesses at a rate greater than or a participant.
